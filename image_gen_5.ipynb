{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0bf5ed0d1bfc6d19a0d1bba5b91c07a091be2c0f3786b839f216821a421533302",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "based on: https://medium.com/analytics-vidhya/transforming-the-world-into-paintings-with-cyclegan-6748c0b85632"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## The Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "data, metadata = tfds.load(\"cycle_gan/monet2photo\",\n",
    "    with_info=True, as_supervised=True)\n",
    "train_x, train_y = data[\"trainA\"], data[\"trainB\"]\n",
    "test_x, test_y = data[\"testA\"], data[\"testB\"]"
   ]
  },
  {
   "source": [
    "## Steup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "# num training epochs\n",
    "EPOCHS = 50\n",
    "\n",
    "# relative importance of the cycle loss to the adversarial loss\n",
    "LAMBDA = 10\n",
    "\n",
    "img_rows, img_cols, channels = 256, 256, 3\n",
    "weight_initializer = RandomNormal(stddev=0.02)\n",
    "\n",
    "gen_g_optimizer = gen_f_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "dis_x_optimizer = dis_y_optimizer = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# TODO: add random cropping\n",
    "def preprocess_image(image, _):\n",
    "    return tf.reshape(\n",
    "        tf.cast(\n",
    "            tf.image.resize(image, (int(img_rows), int(img_cols))),\n",
    "            tf.float32\n",
    "        ) / 127.5 - 1,\n",
    "        (1, img_rows, img_cols, channels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.map(preprocess_image)\n",
    "train_y = train_y.map(preprocess_image)\n",
    "test_x = test_x.map(preprocess_image)\n",
    "test_y = test_y.map(preprocess_image)"
   ]
  },
  {
   "source": [
    "## The Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, LeakyReLU\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "def Ck(inpt, k, use_instancenorm=True):\n",
    "    \"\"\"\n",
    "    Ck denotes a 4 × 4 Convolution-InstanceNorm-LeakyReLU layer \n",
    "    with k filters and stride 2.\n",
    "    \"\"\"\n",
    "    block = Conv2D(\n",
    "        k, \n",
    "        (4, 4), \n",
    "        strides=2, \n",
    "        padding=\"same\", \n",
    "        kernel_initializer=weight_initializer\n",
    "    )(inpt)\n",
    "\n",
    "    if use_instancenorm:\n",
    "        block = InstanceNormalization(axis=-1)(block)\n",
    "\n",
    "    block = LeakyReLU(0.2)(block)\n",
    "\n",
    "    return block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def discriminator():\n",
    "    dis_input = Input(shape=(img_rows, img_cols, channels))\n",
    "\n",
    "    d = Ck(dis_input, 64, False)\n",
    "    d = Ck(d, 128)\n",
    "    d = Ck(d, 256)\n",
    "    d = Ck(d, 512)\n",
    "\n",
    "    d = Conv2D(\n",
    "        1, \n",
    "        (4, 4), \n",
    "        padding=\"same\", \n",
    "        kernel_initializer=weight_initializer\n",
    "    )(d)\n",
    "\n",
    "    dis = Model(dis_input, d)\n",
    "    dis.compile(loss=\"mse\", optimizer=dis_x_optimizer)\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "def dk(k, use_instancenorm=True):\n",
    "    \"\"\"\n",
    "    dk denotes a 3×3 Convolution-InstanceNorm-ReLU with k \n",
    "    filters and stride 2.\n",
    "    \"\"\"\n",
    "    block = Sequential()\n",
    "    block.add(\n",
    "        Conv2D(\n",
    "            k,\n",
    "            (3, 3),\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=weight_initializer\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if use_instancenorm:\n",
    "        block.add(InstanceNormalization(axis=-1))\n",
    "    \n",
    "    block.add(Activation(\"relu\"))\n",
    "\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "def uk(k):\n",
    "    \"\"\"\n",
    "    uk denotes a 3×3 fractional-strided-ConvolutionInstanceNorm-ReLU \n",
    "    layer with k filters and stride ½.\n",
    "    \"\"\"\n",
    "    block = Sequential()\n",
    "    block.add(\n",
    "        Conv2DTranspose(\n",
    "            k,\n",
    "            (3, 3),\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=weight_initializer\n",
    "        )\n",
    "    )\n",
    "\n",
    "    block.add(InstanceNormalization(axis=-1))\n",
    "    block.add(Activation(\"relu\"))\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def generator():\n",
    "    gen_input = Input(shape=(img_rows, img_cols, channels))\n",
    "\n",
    "    encoder_layers = [\n",
    "        dk(64, False),\n",
    "        dk(128),\n",
    "        dk(256),\n",
    "        dk(512),\n",
    "        dk(512),\n",
    "        dk(512),\n",
    "        dk(512),\n",
    "        dk(512,)\n",
    "    ]\n",
    "\n",
    "    decoder_layers = [\n",
    "        uk(512),\n",
    "        uk(512),\n",
    "        uk(512),\n",
    "        uk(512),\n",
    "        uk(256),\n",
    "        uk(128),\n",
    "        uk(64),\n",
    "    ]\n",
    "\n",
    "    gen = gen_input\n",
    "\n",
    "    skips = []\n",
    "    for layer in encoder_layers:\n",
    "        gen = layer(gen)\n",
    "        skips.append(gen)\n",
    "\n",
    "    # reverse and remove first element\n",
    "    skips = skips[::-1][1:]\n",
    "\n",
    "    for skip_layer, layer in zip(skips, decoder_layers):\n",
    "        gen = layer(gen)\n",
    "        gen = Concatenate()([gen, skip_layer])\n",
    "\n",
    "    gen = Conv2DTranspose(\n",
    "        channels, \n",
    "        (3, 3),\n",
    "        strides=2,\n",
    "        padding=\"same\", \n",
    "        kernel_initializer=weight_initializer,\n",
    "        activation=\"tanh\"\n",
    "    )(gen)\n",
    "\n",
    "    return Model(gen_input, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g = generator()\n",
    "generator_f = generator()\n",
    "\n",
    "discriminator_x = discriminator()\n",
    "discriminator_y = discriminator()"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "loss = BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real, generated):\n",
    "    return (loss(tf.ones_like(real), real) \n",
    "        + loss(tf.zeros_like(generated), generated)) * 0.5\n",
    "\n",
    "\n",
    "def gen_loss(validity):\n",
    "    return loss(tf.ones_like(validity), validity)\n",
    "\n",
    "\n",
    "def image_similarity(image1, image2):\n",
    "    return tf.reduce_mean(tf.abs(image1 - image2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def step(real_x, real_y):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # compute discriminator y loss\n",
    "        fake_y = generator_g(real_x, training=True)\n",
    "        gen_g_validity = discriminator_y(fake_y, training=True)\n",
    "        dis_y_loss = discriminator_loss(\n",
    "            discriminator_y(real_y, training=True),\n",
    "            gen_g_validity\n",
    "        )\n",
    "\n",
    "        # compute and apply dicriminator y gradients\n",
    "        with tape.stop_recording():\n",
    "            discriminator_y_gradients = tape.gradient(\n",
    "                dis_y_loss,\n",
    "                discriminator_y.trainable_variables\n",
    "            )\n",
    "\n",
    "            dis_y_optimizer.apply_gradients(\n",
    "                zip(discriminator_y_gradients, discriminator_y.trainable_variables)\n",
    "            )\n",
    "\n",
    "        # compute discriminator x loss\n",
    "        fake_x = generator_f(real_y, training=True)\n",
    "        gen_f_validity = discriminator_x(fake_x, training=True)\n",
    "        dis_x_loss = discriminator_loss(\n",
    "            discriminator_x(real_x, training=True),\n",
    "            gen_f_validity\n",
    "        )\n",
    "\n",
    "        # compute and apply discriminator x gradients\n",
    "        with tape.stop_recording():\n",
    "            discriminator_x_gradients = tape.gradient(\n",
    "                dis_x_loss,\n",
    "                discriminator_x.trainable_variables\n",
    "            )\n",
    "\n",
    "            dis_x_optimizer.apply_gradients(\n",
    "                zip(discriminator_x_gradients, discriminator_x.trainable_variables)\n",
    "            )\n",
    "\n",
    "        # adversarial losses - how real the dis believed the generated images\n",
    "        gen_g_adv_loss = gen_loss(gen_g_validity)\n",
    "        gen_f_adv_loss = gen_loss(gen_f_validity)\n",
    "\n",
    "        # cycle losses - how well a translated image can be re-translated\n",
    "        cyc_x = generator_f(fake_y, training=True)\n",
    "        cyc_x_loss = image_similarity(real_x, cyc_x)\n",
    "        cyc_y = generator_g(fake_x, training=True)\n",
    "        cyc_y_loss = image_similarity(real_y, cyc_y)\n",
    "\n",
    "        # identity loss \n",
    "        id_x = generator_f(real_x, training=True)\n",
    "        id_x_loss = image_similarity(real_x, id_x)\n",
    "        id_y = generator_g(real_y, training=True)\n",
    "        id_y_loss = image_similarity(real_y, id_y)\n",
    "\n",
    "        # generator losses\n",
    "        gen_g_loss = gen_g_adv_loss + (cyc_x_loss + cyc_y_loss) * LAMBDA + id_y_loss * 0.5 * LAMBDA\n",
    "        gen_f_loss = gen_f_adv_loss + (cyc_x_loss + cyc_y_loss) * LAMBDA + id_x_loss * 0.5 * LAMBDA\n",
    "\n",
    "        # compute and apply generator gradients\n",
    "        with tape.stop_recording():\n",
    "            generator_g_gradients = tape.gradient(gen_g_loss, generator_g.trainable_variables)\n",
    "            gen_g_optimizer.apply_gradients(\n",
    "                zip(generator_g_gradients, generator_g.trainable_variables)\n",
    "            )\n",
    "\n",
    "            generator_f_gradients = tape.gradient(gen_f_loss, generator_f.trainable_variables)\n",
    "            gen_f_optimizer.apply_gradients(\n",
    "                zip(generator_f_gradients, generator_f.trainable_variables)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_images():\n",
    "    # sample images\n",
    "    x = next(iter(test_x.shuffle(1000))).numpy()\n",
    "    y = next(iter(test_y.shuffle(1000))).numpy()\n",
    "\n",
    "    # get predictions for those images\n",
    "    y_hat = generator_g.predict(x.reshape((1, img_rows, img_cols, channels)))\n",
    "    x_had = generator_f.predict(y.reshape((1, img_rows, img_cols, channels)))\n",
    "\n",
    "    # plot images\n",
    "    plt.figure(figsize(12, 12))\n",
    "\n",
    "    images = [x[0], y_hat[0], y[0], x_hat[0]]\n",
    "\n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        plt.imshow(images[i] * 0.5 + 0.5)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0\n0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "in user code:\n\n    <ipython-input-65-58833962805f>:69 step  *\n        generator_f_gradients = tape.gradient(gen_f_loss, generator_f.trainable_variables)\n\n    NameError: name 'gen_f_loss' is not defined\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-dcfee535d223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         step(\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: in user code:\n\n    <ipython-input-65-58833962805f>:69 step  *\n        generator_f_gradients = tape.gradient(gen_f_loss, generator_f.trainable_variables)\n\n    NameError: name 'gen_f_loss' is not defined\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    start = time.time()\n",
    "\n",
    "    # Each batch\n",
    "    for k, (real_x, real_y) in enumerate(tf.data.Dataset.zip((train_x, train_y))):\n",
    "        if k % 100 == 0:\n",
    "            print(k)\n",
    "\n",
    "        step(\n",
    "            tf.reshape(real_x, (1, img_rows, img_cols, channels)), \n",
    "            tf.reshape(real_y, (1, img_rows, img_cols, channels))\n",
    "        )\n",
    "\n",
    "    generate_images()\n",
    "    print(f\"Time taken: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}